{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import glob as glob\n",
    "import slate3k as slate\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "folder_path = r'C:\\Users\\Bhagya\\Resume Analyzer\\ACTUAL PROJECT\\Resumes_SF\\*.pdf'\n",
    "resume = []\n",
    "names = []\n",
    "restr = ''\n",
    "\n",
    "for filenames in glob.glob(folder_path):\n",
    "    names.append(filenames)\n",
    "    with open(filenames, 'rb') as fi:\n",
    "        doc = slate.PDF(fi, word_margin=0)\n",
    "        for i in range(len(doc)):\n",
    "            string = doc[i]\n",
    "            restr = restr+string.replace('\\xa0', ' ').replace('\\x0c', ' ') \n",
    "    resume.append(restr)\n",
    "    restr = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Candidates = []\n",
    "for n in names:\n",
    "    Candidates.append(n.split('Resumes_SF\\\\')[1].split('.pdf')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Resumes parsed: 201\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Resumes parsed:\", len(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Candidates: 201\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Candidates:\", len(Candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    Removes new line and unwanted page of values from the text\n",
    "    '''\n",
    "    text1 = re.compile('[%s]' % '(\\\\n)*(\\\\x0c)*').sub(' ', text)  \n",
    "    text2 = re.compile(r'Page [0-9]+ of [0-9]+').sub(' ', text1)  \n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''\n",
    "    Removes punctuation\n",
    "    Did not remove few characters such as .,$%-~:;?!\n",
    "    '''\n",
    "    clean_punct =  re.compile('[%s]' % re.escape('\"#&\\()*+/<=>@[\\\\]^_{|}')).sub(' ', text) \n",
    "    return clean_punct                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_treatment(text):\n",
    "    '''\n",
    "    Replacing unwanted characters with space\n",
    "    '''\n",
    "    text = text.replace(\"\\x00\", '').replace(\"\\x01\", '').replace(\"\\x02\", '').replace(\"\\x03\", '') \\\n",
    "    .replace(\"\\x04\", '').replace(\"\\x05\", '').replace(\"\\x06\", '').replace(\"\\x07\", '').replace(\"\\x08\", '') \\\n",
    "    .replace(\"\\x0e\", '').replace(\"\\x11\", '').replace(\"\\x12\", '').replace(\"\\x10\", '').replace(\"\\x19\", '') \\\n",
    "    .replace(\"\\x1b\", '').replace(\"\\x14\", '').replace(\"\\x15\", '').replace('/', '').replace('=', '').replace(\"〓\", \"\") \\\n",
    "    .replace(\"»\", \"\").replace(\"«\", \"\").replace(\"¬\", \"\").replace('`', '').replace(\"•\", \"\").replace(\"▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬\",\"\")\\\n",
    "    .replace(\"”\", \"\").replace(\"§\", \"\").replace(\"¨\", \"\").replace(\"©\", \"\").replace(\"›\", \"\").replace(\"■\", \"\").replace(\"ifttt\", \"\")\\\n",
    "    .replace(\"→\", \"\").replace(\"⇨\", \"\").replace(\"∎\", \"\").replace(\"√\", \"\").replace(\"□\", \"\").replace(\"~~~\", \"\").replace(\"★\", \"\")\\\n",
    "    .replace(\"*\", \"\").replace(\"&\", \"\").replace(\"►\", \"\").replace(\"◊\", \"\").replace(\"☞\", \"\").replace(\"#\", \"\")\\\n",
    "    .replace(\"❖\", \"\").replace(\"➠\", \"\").replace(\"➢\", \"\").replace(\"\", \"\").replace(\"✓\", \"\").replace(\"--\",\"\") \\\n",
    "    .replace(\"√\", \"\").replace(\"✔\", \"\").replace(\"♦\", \"\").replace(\"◦\", \"\").replace(\"●\", \"\").replace(\"▫\", \"\")\\\n",
    "    .replace(\"▪\", \"\").replace(\"…\", \"\").replace(\"þ\", \"\").replace(\"®\", \"\").replace('', '').replace(\"...\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masters(text):\n",
    "    '''\n",
    "    Filtering people who have a Masters/PhD degree with value 1 from the Education column\n",
    "    '''\n",
    "    patterns = re.compile(\"(Master's|Master|M.S.|MS|M.Sc.|MSc|PhD|Ph.D.|Honors)\")\n",
    "    #print('Looking for \"%s\" in \"%s\" ->' % (patterns, text))\n",
    "    if patterns.search(text):\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experience(text):\n",
    "    text1 =  re.findall(r\"([a-zA-Z]+\\s\\d+\\s-\\s\\D+\\s\\d*\\s\\s?)(\\d+\\syears?\\s\\d+ months?|\\d+ years?|\\d+ months?)\",text)\n",
    "    '''\n",
    "    text1: Finding strings of pattern 'June 2011 - December 2012  ', '1 year 7 months'\n",
    "    Finding the total experience of a person\n",
    "    '''\n",
    "    years = 0\n",
    "    months= 0 \n",
    "    for i in text1:\n",
    "        match_years = re.search(\"[0-9]+\\syears?\",i[1])     # to get all the years\n",
    "        if match_years != None:\n",
    "            yr = int(match_years.group()[0])\n",
    "            years += yr\n",
    "        match_months = re.search(\"[0-9]+\\smonths?\",i[1])   # to get all the months\n",
    "        if match_months != None:\n",
    "            month = int(match_months.group()[0:2])\n",
    "            months += month\n",
    "    total_exp = round(years + (months/12),2)\n",
    "    return total_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_contact(text):\n",
    "    '''\n",
    "    Filtering the Contact column to get any piece of contact information such as Email or Github or Phone number \n",
    "    '''\n",
    "    if re.findall(r'[a-zA-Z0-9.-]+@[a-zA-Z-]+\\.com+', text):\n",
    "        value = re.findall(r'[a-zA-Z0-9.-]+@[a-zA-Z-]+\\.com+', text)[0]\n",
    "    elif re.findall(r'github\\.com/\\s?[a-zA-Z0-9_]+', text):\n",
    "        value = re.findall(r'github\\.com/\\s?[a-zA-Z0-9_]+', text)[0]\n",
    "    elif re.findall(r'\\d{3}-\\d{3}-\\d{4}', text):\n",
    "        value = re.findall(r'\\d{3}-\\d{3}-\\d{4}', text)[0]\n",
    "    else:\n",
    "        value = None    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Candidate_Name':Candidates,'Resume':resume})\n",
    "df2 = df[((df['Resume'].str.contains('\\n\\nSummary\\n\\n')) | (df['Resume'].str.contains('\\n \\n Summary\\n\\n'))) \n",
    "          & ((df['Resume'].str.contains('\\n\\nExperience\\n\\n')) | (df['Resume'].str.contains('\\n \\n Experience\\n\\n'))) \n",
    "          & ((df['Resume'].str.contains('\\n\\nEducation\\n\\n'))|(df['Resume'].str.contains('\\n \\n Education\\n\\n')))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes having summary, experience and education fields: 143\n"
     ]
    }
   ],
   "source": [
    "print(\"Total resumes having summary, experience and education fields:\", df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating different fields by extracting data\n",
    "df2['Contact'] = df2['Resume'].str.split('Contact\\n\\n').str[1].str.split('\\n\\nSummary').str[0]\n",
    "df2['Summary'] = df2['Resume'].str.split('Summary\\n\\n').str[1].str.split('\\n\\nExperience').str[0]\n",
    "df2['Experience'] = df2['Resume'].str.split('Experience\\n\\n').str[1].str.split('\\n\\nEducation').str[0]\n",
    "df2['Education'] = df2['Resume'].str.split('Education\\n\\n').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above functions\n",
    "df2['Contact']    = df2['Contact'].apply(clean_text)\n",
    "df2['Summary']    = df2['Summary'].apply(clean_text).apply(remove_punctuation).apply(text_treatment)\n",
    "df2['Experience'] = df2['Experience'].apply(clean_text).apply(remove_punctuation).apply(text_treatment)\n",
    "df2['Education']  = df2['Education'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)                              # to increase column width size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting useful information from contacts\n",
    "df2[\"Masters\"] = df2[\"Education\"].apply(masters)\n",
    "df2['Total_Experience'] = df2['Experience'].apply(get_experience)\n",
    "df2['Linkedin_Profile'] = df2['Contact'].str.findall(r'www.linkedin.com/in/\\s?[a-zA-Z0-9_%-]+\\s*?[a-zA-Z0-9_%-]+\\s?\\s?[L$]').apply(''.join).str.split(' L').str[0].replace(\" \", '', regex=True)\n",
    "df2['Contact_Info'] = df2['Contact'].apply(Get_contact)\n",
    "df2.drop([\"Resume\", \"Contact\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Education</th>\n",
       "      <th>Masters</th>\n",
       "      <th>Total_Experience</th>\n",
       "      <th>Linkedin_Profile</th>\n",
       "      <th>Contact_Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aadil Hussaini</td>\n",
       "      <td>Experienced Data Scientist with strong business acumen, with a demonstrated history of driving p...</td>\n",
       "      <td>Lyft  Data Scientist  November 2019 - Present  5 months   Facebook  3 years 5 months  Data Scien...</td>\n",
       "      <td>Stanford University  Graduate Certificate, Data Mining and Statistics ·  2015   Univer...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.50</td>\n",
       "      <td>www.linkedin.com/in/aadilhussaini</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhimanyu Mitra</td>\n",
       "      <td>Experienced Researcher in Data Science with a passion for data- driven decision making and build...</td>\n",
       "      <td>Walmart Labs  7 years 1 month  Principal Data Scientist  September 2016 - Present  3 years 7 mon...</td>\n",
       "      <td>Cornell University  PhD, Operations Research, Concentration: Applied Probability &amp;  Statistics ·...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.67</td>\n",
       "      <td>www.linkedin.com/in/abhimanyu-mitra-84848011</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alison Hung</td>\n",
       "      <td>Certified Scrum agile product development expert. Experienced Product Manager with a demonstrate...</td>\n",
       "      <td>Advantech  Product Manager  June 2016 - Present  3 years 10 months  San Francisco Bay Area  - Ma...</td>\n",
       "      <td>University of Illinois at Urbana-Champaign  Master of Science  MS , Technology Management ·  201...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.33</td>\n",
       "      <td>www.linkedin.com/in/alisonhung</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alvira Swalin</td>\n",
       "      <td>IIT Bombay graduate  2016  and MSDS alum at USF. Keen to apply Mathematical, Statistical and Mac...</td>\n",
       "      <td>Uber  1 year 8 months  Data Scientist II  February 2020 - Present  2 months  San Francisco Bay A...</td>\n",
       "      <td>University of San Francisco  Master's degree, Analytics ·  2017 - 2018   Indian Institute of Tec...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.33</td>\n",
       "      <td>www.linkedin.com/in/alvira-swalin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amrit Bulusu</td>\n",
       "      <td>With a strong background in Cognitive Science and User Experience research, I am passionate in m...</td>\n",
       "      <td>Samsung Electronics America  2 years 3 months  Data Scientist  January 2020 - Present  3 months ...</td>\n",
       "      <td>Rice University  Doctor of Philosophy  Ph.D. , Psychology ·  2010 - 2016   Rice University  Mast...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.58</td>\n",
       "      <td>www.linkedin.com/in/yuhsuan1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Candidate_Name  \\\n",
       "0   Aadil Hussaini   \n",
       "1  Abhimanyu Mitra   \n",
       "2      Alison Hung   \n",
       "3    Alvira Swalin   \n",
       "4     Amrit Bulusu   \n",
       "\n",
       "                                                                                               Summary  \\\n",
       "0  Experienced Data Scientist with strong business acumen, with a demonstrated history of driving p...   \n",
       "1  Experienced Researcher in Data Science with a passion for data- driven decision making and build...   \n",
       "2  Certified Scrum agile product development expert. Experienced Product Manager with a demonstrate...   \n",
       "3  IIT Bombay graduate  2016  and MSDS alum at USF. Keen to apply Mathematical, Statistical and Mac...   \n",
       "4  With a strong background in Cognitive Science and User Experience research, I am passionate in m...   \n",
       "\n",
       "                                                                                            Experience  \\\n",
       "0  Lyft  Data Scientist  November 2019 - Present  5 months   Facebook  3 years 5 months  Data Scien...   \n",
       "1  Walmart Labs  7 years 1 month  Principal Data Scientist  September 2016 - Present  3 years 7 mon...   \n",
       "2  Advantech  Product Manager  June 2016 - Present  3 years 10 months  San Francisco Bay Area  - Ma...   \n",
       "3  Uber  1 year 8 months  Data Scientist II  February 2020 - Present  2 months  San Francisco Bay A...   \n",
       "4  Samsung Electronics America  2 years 3 months  Data Scientist  January 2020 - Present  3 months ...   \n",
       "\n",
       "                                                                                             Education  \\\n",
       "0            Stanford University  Graduate Certificate, Data Mining and Statistics ·  2015   Univer...   \n",
       "1  Cornell University  PhD, Operations Research, Concentration: Applied Probability &  Statistics ·...   \n",
       "2  University of Illinois at Urbana-Champaign  Master of Science  MS , Technology Management ·  201...   \n",
       "3  University of San Francisco  Master's degree, Analytics ·  2017 - 2018   Indian Institute of Tec...   \n",
       "4  Rice University  Doctor of Philosophy  Ph.D. , Psychology ·  2010 - 2016   Rice University  Mast...   \n",
       "\n",
       "   Masters  Total_Experience                              Linkedin_Profile  \\\n",
       "0        1              7.50             www.linkedin.com/in/aadilhussaini   \n",
       "1        1              8.67  www.linkedin.com/in/abhimanyu-mitra-84848011   \n",
       "2        1              7.33                www.linkedin.com/in/alisonhung   \n",
       "3        1              3.33             www.linkedin.com/in/alvira-swalin   \n",
       "4        1             12.58                  www.linkedin.com/in/yuhsuan1   \n",
       "\n",
       "  Contact_Info  \n",
       "0         None  \n",
       "1         None  \n",
       "2         None  \n",
       "3         None  \n",
       "4         None  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the dataframe into a csv file \n",
    "df2.to_csv('Resume_Data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
